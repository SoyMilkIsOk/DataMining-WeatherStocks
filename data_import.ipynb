{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f436fb-64f9-4f4c-aceb-298d3727ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Metadata specs #\n",
    "\n",
    "metadata_col_specs = [\n",
    "    (0,  12),\n",
    "    (12, 21),\n",
    "    (21, 31),\n",
    "    (31, 38),\n",
    "    (38, 41),\n",
    "    (41, 72),\n",
    "    (72, 76),\n",
    "    (76, 80),\n",
    "    (80, 86)\n",
    "]\n",
    "\n",
    "metadata_names = [\n",
    "    \"ID\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"ELEVATION\",\n",
    "    \"STATE\",\n",
    "    \"NAME\",\n",
    "    \"GSN FLAG\",\n",
    "    \"HCN/CRN FLAG\",\n",
    "    \"WMO ID\"]\n",
    "\n",
    "metadata_dtype = {\n",
    "    \"ID\": str,\n",
    "    \"STATE\": str,\n",
    "    \"NAME\": str,\n",
    "    \"GSN FLAG\": str,\n",
    "    \"HCN/CRN FLAG\": str,\n",
    "    \"WMO ID\": str\n",
    "    }\n",
    "\n",
    "\n",
    "# Data specs #\n",
    "\n",
    "data_header_names = [\n",
    "    \"ID\",\n",
    "    \"YEAR\",\n",
    "    \"MONTH\",\n",
    "    \"ELEMENT\"]\n",
    "\n",
    "data_header_col_specs = [\n",
    "    (0,  11),\n",
    "    (11, 15),\n",
    "    (15, 17),\n",
    "    (17, 21)]\n",
    "\n",
    "data_header_dtypes = {\n",
    "    \"ID\": str,\n",
    "    \"YEAR\": int,\n",
    "    \"MONTH\": int,\n",
    "    \"ELEMENT\": str}\n",
    "\n",
    "data_col_names = [[\n",
    "    \"VALUE\" + str(i + 1),\n",
    "    \"MFLAG\" + str(i + 1),\n",
    "    \"QFLAG\" + str(i + 1),\n",
    "    \"SFLAG\" + str(i + 1)]\n",
    "    for i in range(31)]\n",
    "# Join sub-lists\n",
    "data_col_names = sum(data_col_names, [])\n",
    "\n",
    "data_replacement_col_names = [[\n",
    "    (\"VALUE\", i + 1),\n",
    "    (\"MFLAG\", i + 1),\n",
    "    (\"QFLAG\", i + 1),\n",
    "    (\"SFLAG\", i + 1)]\n",
    "    for i in range(31)]\n",
    "# Join sub-lists\n",
    "data_replacement_col_names = sum(data_replacement_col_names, [])\n",
    "data_replacement_col_names = pd.MultiIndex.from_tuples(\n",
    "    data_replacement_col_names,\n",
    "    names=['VAR_TYPE', 'DAY'])\n",
    "\n",
    "data_col_specs = [[\n",
    "    (21 + i * 8, 26 + i * 8),\n",
    "    (26 + i * 8, 27 + i * 8),\n",
    "    (27 + i * 8, 28 + i * 8),\n",
    "    (28 + i * 8, 29 + i * 8)]\n",
    "    for i in range(31)]\n",
    "data_col_specs = sum(data_col_specs, [])\n",
    "\n",
    "data_col_dtypes = [{\n",
    "    \"VALUE\" + str(i + 1): int,\n",
    "    \"MFLAG\" + str(i + 1): str,\n",
    "    \"QFLAG\" + str(i + 1): str,\n",
    "    \"SFLAG\" + str(i + 1): str}\n",
    "    for i in range(31)]\n",
    "data_header_dtypes.update({k: v for d in data_col_dtypes for k, v in d.items()})\n",
    "\n",
    "\n",
    "# Reading functions #\n",
    "\n",
    "def read_station_metadata(filename=\"ghcnd-stations.txt\"):\n",
    "    \"\"\"Reads in station metadata\n",
    "\n",
    "    :filename: ghcnd station metadata file.\n",
    "    :returns: station metadata as a pandas Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.read_fwf(filename, metadata_col_specs, names=metadata_names,\n",
    "                     index_col='ID', dtype=metadata_dtype)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_ghcn_data_file(filename=\"USW00094789.dly\",\n",
    "                        variables=None, include_flags=False,\n",
    "                        dropna='all'):\n",
    "    \"\"\"Reads in all data from a GHCN .dly data file\n",
    "\n",
    "    :param filename: path to file\n",
    "    :param variables: list of variables to include in output dataframe\n",
    "        e.g. ['TMAX', 'TMIN', 'PRCP']\n",
    "    :param include_flags: Whether to include data quality flags in the final output\n",
    "    :returns: Pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_fwf(\n",
    "        filename,\n",
    "        colspecs=data_header_col_specs + data_col_specs,\n",
    "        names=data_header_names + data_col_names,\n",
    "        index_col=data_header_names,\n",
    "        dtype=data_header_dtypes\n",
    "        )\n",
    "\n",
    "    if variables is not None:\n",
    "        df = df[df.index.get_level_values('ELEMENT').isin(variables)]\n",
    "\n",
    "    df.columns = data_replacement_col_names\n",
    "\n",
    "    if not include_flags:\n",
    "        df = df.loc[:, ('VALUE', slice(None))]\n",
    "        df.columns = df.columns.droplevel('VAR_TYPE')\n",
    "\n",
    "    df = df.stack(level='DAY').unstack(level='ELEMENT')\n",
    "\n",
    "    if dropna:\n",
    "        df.replace(-9999.0, np.nan, inplace=True)\n",
    "        df.dropna(how=dropna, inplace=True)\n",
    "\n",
    "    # replace the entire index with the date.\n",
    "    # This loses the station ID index column!\n",
    "    # This will usuall fail if dropna=False, since months with <31 days\n",
    "    # still have day=31 columns\n",
    "    df.index = pd.to_datetime(\n",
    "        df.index.get_level_values('YEAR') * 10000 +\n",
    "        df.index.get_level_values('MONTH') * 100 +\n",
    "        df.index.get_level_values('DAY'),\n",
    "        format='%Y%m%d')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = read_ghcn_data_file()\n",
    "df['TMAX'] = df['TMAX'] / 10\n",
    "#print(df)\n",
    "data = df[['PRCP','SNOW','TMAX']].copy(deep=True)\n",
    "data['Total Rain/Snow'] = (df['PRCP'].fillna(0)/10) + df['SNOW'].fillna(0)\n",
    "bins = [-1, 100, 500, 2000]\n",
    "data['binned'] = pd.cut(data['Total Rain/Snow'], bins, labels = ['Low', 'Med', 'High'])\n",
    "\n",
    "\n",
    "# print(data)\n",
    "\n",
    "\n",
    "### STOCKS DATA ###\n",
    "\n",
    "df_stocks = pd.read_csv('spy_data.csv')\n",
    "df_stocks['Date'] = pd.to_datetime(df_stocks['Date'])\n",
    "df_stocks = df_stocks.set_index('Date')\n",
    "df_stocks['% Change'] = (df_stocks['Close'] - df_stocks['Open'])/df_stocks['Open']*100 \n",
    "df_stocks = df_stocks.drop(['High','Low','Open','Close','OpenInt'], axis=1)\n",
    "\n",
    "#print(df_stocks)\n",
    "\n",
    "### NEW WEATHER DATA ###\n",
    "\n",
    "df_weather = pd.read_csv('NYCweather-data.csv')\n",
    "df_weather['Date'] = pd.to_datetime(df_weather['DATE'])\n",
    "df_weather = df_weather.set_index('DATE')\n",
    "df_weather['TOTALPRCP'] = df_weather['PRCP'] + df_weather['SNOW'] + df_weather['SNWD']\n",
    "df_weather = df_weather.drop(['TAVG','PRCP','SNOW', 'SNWD','STATION'], axis=1)\n",
    "bins = [-1, 1, 4, 100]\n",
    "df_weather['binned'] = pd.cut(df_weather['TOTALPRCP'], bins, labels = ['Low', 'Med', 'High'])\n",
    "\n",
    "#print(df_weather)\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_stocks,\n",
    "    df_weather,\n",
    "    how=\"left\",\n",
    "    on='Date',\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "\n",
    "#print(df_merged)\n",
    "\n",
    "ag_data = pd.read_csv(\"dba.us.txt\", sep = \",\")\n",
    "ag_data['Date'] = pd.to_datetime(ag_data['Date'])\n",
    "ag_data = ag_data.set_index('Date')\n",
    "ag_data['% Change'] = (ag_data['Close'] - ag_data['Open'])/ag_data['Open']*100 \n",
    "ag_data = ag_data.drop(['High','Low','Open','Close','OpenInt'], axis=1)\n",
    "\n",
    "\n",
    "ag_merged = pd.merge(\n",
    "    ag_data,\n",
    "    df_weather,\n",
    "    how=\"left\",\n",
    "    on='Date',\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "  \n",
    "# display DataFrame\n",
    "#print(ag_merged)\n",
    "\n",
    "\n",
    "names = ['spy.us.txt', 'ivv.us.txt', 'vti.us.txt', 'voo.us.txt', 'qqq.us.txt', 'vea.us.txt', 'vtv.us.txt', 'iefa.us.txt', 'agg.us.txt', 'bnd.us.txt']\n",
    "stocks = {}\n",
    "for stock in names: \n",
    "    stocks[stock] = pd.read_csv(stock)\n",
    "    stocks[stock]['Date'] = pd.to_datetime(stocks[stock]['Date'])\n",
    "    stocks[stock] = stocks[stock].set_index('Date')\n",
    "    stocks[stock]['% Change'] = (stocks[stock]['Close'] - stocks[stock]['Open'])/stocks[stock]['Open']*100 \n",
    "    stocks[stock] = stocks[stock].drop(['High','Low','Open','Close','OpenInt'], axis=1)\n",
    "    \n",
    "etfs_avg = pd.concat((stocks['spy.us.txt'], stocks['ivv.us.txt'], stocks['vti.us.txt'], stocks['voo.us.txt']\\\n",
    "                 , stocks['qqq.us.txt'], stocks['vea.us.txt'], stocks['vtv.us.txt'], stocks['iefa.us.txt'], stocks['agg.us.txt'], stocks['bnd.us.txt']))\n",
    "etfs_avg = etfs_avg.groupby(etfs_avg.index).mean()\n",
    "\n",
    "#etfs_avg['Date'] = pd.to_datetime(etfs_avg['Date'])\n",
    "#etfs_avg = etfs_avg.set_index('Date')\n",
    "#etfs_avg['% Change'] = (etfs_avg['Close'] - etfs_avg['Open'])/etfs_avg['Open']*100 \n",
    "#etfs_avg = etfs_avg.drop(['High','Low','Open','Close','OpenInt'], axis=1)\n",
    "#print(etfs_avg)\n",
    "\n",
    "etfs_merged = pd.merge(\n",
    "    etfs_avg,\n",
    "    df_weather,\n",
    "    how=\"left\",\n",
    "    on='Date',\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4753bf4-1b67-46ce-8ea3-a91671194039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
